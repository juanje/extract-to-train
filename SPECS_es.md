# Especificaciones del Proyecto Extract-to-Train

## üéØ Resumen del Proyecto

**Extract-to-Train** es una herramienta CLI educativa que extrae informaci√≥n de documentos PDF y Markdown y genera datasets de Q&A de alta calidad en formatos optimizados para fine-tuning de LLM con t√©cnicas LoRA/QLoRA. El proyecto enfatiza el aprendizaje a trav√©s de la transparencia, proporcionando insights educativos en cada paso del proceso de creaci√≥n de datasets.

**Capacidades clave para procesamiento a gran escala:**
- Guardado progresivo con recuperaci√≥n de interrupciones
- Limitaci√≥n de chunks para testing y evaluaci√≥n de calidad
- Procesamiento multiidioma de documentos con generaci√≥n consciente del idioma

### Objetivos Principales

1. **Extraer** informaci√≥n estructurada de documentos PDF y Markdown usando docling y parsers nativos
2. **Generar** pares diversos de pregunta-respuesta usando LLMs locales v√≠a Ollama
3. **Validar** y criticar el dataset generado para asegurar la calidad
4. **Exportar** en formatos est√°ndar compatibles con frameworks populares de fine-tuning
5. **Educar** a los usuarios sobre mejores pr√°cticas de creaci√≥n de datasets y flujos de trabajo de fine-tuning

### Objetivos Educativos

- Demostrar t√©cnicas de procesamiento de documentos PDF y Markdown
- Mostrar c√≥mo crear datasets de entrenamiento de alta calidad desde varias fuentes
- Explicar ingenier√≠a de prompts para LLM en generaci√≥n de datasets
- Ilustrar validaci√≥n de datasets y control de calidad
- Proporcionar experiencia pr√°ctica con formatos de datos para fine-tuning

## üèóÔ∏è Arquitectura del Proyecto

```
extract-to-train/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ extract_to_train/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ cli.py                    # Punto de entrada CLI principal
‚îÇ       ‚îú‚îÄ‚îÄ core/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ pipeline.py           # Pipeline principal de procesamiento
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ extractor.py          # Extracci√≥n PDF con docling
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ generator.py          # Generaci√≥n Q&A con LLMs
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ validator.py          # Validaci√≥n y control de calidad del dataset
‚îÇ       ‚îú‚îÄ‚îÄ llm/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ client.py             # Cliente Ollama con LangChain
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ prompts.py            # Plantillas de prompts educativas
‚îÇ       ‚îú‚îÄ‚îÄ models/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ dataset.py            # Modelos Pydantic para formatos de dataset
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ config.py             # Modelos de configuraci√≥n
‚îÇ       ‚îî‚îÄ‚îÄ utils/
‚îÇ           ‚îú‚îÄ‚îÄ __init__.py
‚îÇ           ‚îú‚îÄ‚îÄ config.py             # Configuraci√≥n de aplicaci√≥n
‚îÇ           ‚îú‚îÄ‚îÄ stats.py              # Estad√≠sticas y an√°lisis de dataset
‚îÇ           ‚îú‚îÄ‚îÄ logger.py             # Configuraci√≥n de logging educativo
‚îÇ           ‚îî‚îÄ‚îÄ file_handler.py       # Utilidades de I/O de archivos
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îú‚îÄ‚îÄ integration/
‚îÇ   ‚îî‚îÄ‚îÄ fixtures/
‚îú‚îÄ‚îÄ examples/
‚îÇ   ‚îú‚îÄ‚îÄ sample_academic_paper.pdf
‚îÇ   ‚îú‚îÄ‚îÄ sample_tutorial.pdf
‚îÇ   ‚îú‚îÄ‚îÄ sample_report.pdf
‚îÇ   ‚îú‚îÄ‚îÄ expected_outputs/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ academic_alpaca.jsonl
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tutorial_sharegpt.jsonl
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ report_openai.jsonl
‚îÇ   ‚îî‚îÄ‚îÄ tutorial.md
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ getting_started.md
‚îÇ   ‚îú‚îÄ‚îÄ configuration.md
‚îÇ   ‚îî‚îÄ‚îÄ best_practices.md
‚îú‚îÄ‚îÄ pyproject.toml
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ SPEC.md
‚îî‚îÄ‚îÄ .gitignore
```

## üîß Stack Tecnol√≥gico

### Dependencias Principales
- **Procesamiento PDF**: `docling` - Extracci√≥n robusta de PDF preservando estructura
- **Procesamiento Markdown**: `markdown` - Parsing y procesamiento nativo de Markdown
- **Framework LLM**: `langchain` + `langchain-community` - Orquestaci√≥n de LLM
- **LLMs Locales**: `ollama` - Servicio de modelos locales
- **Validaci√≥n de Datos**: `pydantic` v2 - Modelos de datos type-safe
- **Framework CLI**: `typer` - Interfaz CLI moderna y educativa
- **Cliente HTTP**: `httpx` - HTTP as√≠ncrono para API Ollama

### Dependencias de Desarrollo
- **Gesti√≥n de Entorno**: `uv` - Gesti√≥n de dependencias y entorno
- **Calidad de C√≥digo**: `ruff` - Linting y formateo
- **Testing**: `pytest` + `pytest-asyncio` + `pytest-cov`
- **Verificaci√≥n de Tipos**: `mypy`

### Requerimientos de Modelos
- **Ollama**: Instalaci√≥n local requerida
- **Modelos Optimizados** (basado en modelos locales disponibles): 
  - `llama3.1:8B` - Principal para generaci√≥n Q&A (mejor seguimiento de instrucciones)
  - `deepseek-r1:8B` - Principal para validaci√≥n (razonamiento y an√°lisis superior)
  - `mistral:7B` - Alternativa para generaci√≥n (optimizado para velocidad)
  - `llama3:8B` - Opci√≥n de respaldo

## üìä Formatos de Dataset

La herramienta soporta tres formatos est√°ndar de la industria compatibles con los principales frameworks de fine-tuning:

### 1. Formato Alpaca
**Compatible con**: Axolotl, Unsloth, HuggingFace Transformers + PEFT

```jsonl
{"instruction": "¬øQu√© es machine learning seg√∫n el documento?", "input": "", "output": "Machine learning es una rama de la inteligencia artificial que permite a las computadoras aprender y mejorar autom√°ticamente de la experiencia sin ser expl√≠citamente programadas para cada tarea espec√≠fica."}
{"instruction": "Explica el concepto mencionado en el documento", "input": "redes neuronales convolucionales", "output": "Las Redes Neuronales Convolucionales (CNNs) son un tipo especializado de red neuronal artificial dise√±ado espec√≠ficamente para procesar datos estructurados en grilla como im√°genes. Usan operaciones de convoluci√≥n para detectar caracter√≠sticas locales y patrones espaciales."}
```

### 2. Formato ShareGPT
**Compatible con**: Axolotl, Unsloth

```jsonl
{"conversations": [{"from": "human", "value": "Seg√∫n el documento, ¬øqu√© ventajas tienen las redes neuronales?"}, {"from": "gpt", "value": "Seg√∫n el documento, las principales ventajas de las redes neuronales son: 1) Capacidad de aprender patrones complejos no lineales, 2) Adaptabilidad a diferentes tipos de datos, 3) Mejora autom√°tica con m√°s datos de entrenamiento."}]}
```

### 3. Formato OpenAI
**Compatible con**: HuggingFace Transformers + PEFT

```jsonl
{"messages": [{"role": "system", "content": "Eres un experto que responde preguntas basadas en documentos t√©cnicos."}, {"role": "user", "content": "¬øQu√© dice el documento sobre algoritmos de optimizaci√≥n?"}, {"role": "assistant", "content": "El documento describe varios algoritmos de optimizaci√≥n incluyendo SGD, Adam y RMSprop, explicando que Adam combina las ventajas de AdaGrad y RMSprop para lograr una convergencia m√°s r√°pida y estable."}]}
```

## ü§ñ Configuraci√≥n LLM

### Estrategia de Selecci√≥n de Modelos

#### Modelo de Generaci√≥n
- **Principal**: `llama3.1:8B`
- **Temperatura**: `0.3`
- **Ventana de Contexto**: `4096 tokens`
- **Justificaci√≥n**: Modelo Llama m√°s reciente con mejor seguimiento de instrucciones y consistencia para generaci√≥n diversa de preguntas

#### Modelo de Validaci√≥n  
- **Principal**: `deepseek-r1:8B`
- **Temperatura**: `0.1`
- **Ventana de Contexto**: `4096 tokens`
- **Justificaci√≥n**: Modelo de razonamiento superior dise√±ado espec√≠ficamente para an√°lisis, cr√≠tica y evaluaci√≥n de calidad

### Configuraciones de Modelos Educativas

```python
EDUCATIONAL_CONFIGS = {
    "extraction": {
        "name": "llama3.1:8B",
        "temperature": 0.3,
        "context_window": 4096,
        "explanation": "Modelo Llama m√°s reciente con mejor seguimiento de instrucciones y creatividad balanceada para generaci√≥n diversa de preguntas"
    },
    "validation": {
        "name": "deepseek-r1:8B", 
        "temperature": 0.1,
        "context_window": 4096,
        "explanation": "Modelo de razonamiento superior dise√±ado para an√°lisis y cr√≠tica - proporciona evaluaci√≥n de calidad m√°s exhaustiva que modelos generales"
    }
}
```

### Beneficios de la Configuraci√≥n Optimizada

Esta configuraci√≥n aprovecha los mejores modelos locales disponibles para cada tarea espec√≠fica:

#### ¬øPor qu√© Llama 3.1:8B para Generaci√≥n?
- **Seguimiento de Instrucciones Mejorado**: Entrenamiento mejorado para prompts complejos y estructurados
- **Mejor Comprensi√≥n de Contexto**: Capacidad superior para mantener coherencia a trav√©s de contextos largos
- **Formato de Salida Consistente**: Generaci√≥n m√°s confiable de estructura JSON
- **Reducci√≥n de Alucinaciones**: Mejor adherencia al contenido del documento fuente

#### ¬øPor qu√© DeepSeek-R1:8B para Validaci√≥n?
- **Razonamiento Especializado**: Construido espec√≠ficamente para tareas de an√°lisis y pensamiento cr√≠tico
- **Evaluaci√≥n de Calidad Superior**: Evaluaci√≥n m√°s matizada de la calidad de pares Q&A
- **Retroalimentaci√≥n Detallada**: Mejor en identificar problemas espec√≠ficos y proporcionar sugerencias accionables
- **Objetividad**: Modelo separado asegura validaci√≥n imparcial independiente de la generaci√≥n

#### Configuraciones Alternativas
```python
# Optimizado para velocidad (procesamiento m√°s r√°pido)
SPEED_CONFIG = {
    "extraction": {"name": "mistral:7B", "temperature": 0.3},
    "validation": {"name": "mistral:7B", "temperature": 0.1}
}

# Enfocado en consistencia (mismo modelo para ambas tareas)
CONSISTENCY_CONFIG = {
    "extraction": {"name": "llama3.1:8B", "temperature": 0.3},
    "validation": {"name": "llama3.1:8B", "temperature": 0.05}
}
```

## üìã Modelos de Datos

### Modelos Principales

```python
class DatasetFormat(str, Enum):
    ALPACA = "alpaca"
    SHAREGPT = "sharegpt" 
    OPENAI = "openai"

class QAPair(BaseModel):
    id: str
    question: str
    answer: str
    context: str
    difficulty: Literal["easy", "medium", "hard"]
    question_type: Literal["factual", "inferential", "comparative", "analytical"]
    confidence_score: float
    source_page: Optional[int] = None
    
class ValidationResult(BaseModel):
    is_valid: bool
    accuracy_score: int  # 0-10
    completeness_score: int  # 0-10
    clarity_score: int  # 0-10
    training_value_score: int  # 0-10
    issues: List[str]
    suggestions: List[str]

class DatasetStats(BaseModel):
    total_pairs: int
    avg_question_length: int
    avg_answer_length: int
    difficulty_distribution: Dict[str, int]
    question_type_distribution: Dict[str, int]
    pages_covered: int
    estimated_tokens: int

class Dataset(BaseModel):
    metadata: Dict[str, Any]
    qa_pairs: List[QAPair]
    validation_summary: ValidationResult
    stats: DatasetStats
```

## üéõÔ∏è Interfaz CLI

### Comandos Principales

#### Comando Extract
```bash
extract-to-train extract [OPTIONS] PDF_PATH
```

**Opciones:**
- `--output, -o`: Ruta del archivo de salida (por defecto: `dataset.jsonl`)
- `--format`: Formato de dataset (`alpaca`|`sharegpt`|`openai`, por defecto: `alpaca`)
- `--max-pairs`: M√°ximo de pares Q&A a generar (por defecto: 100)
- `--chunk-size`: Tama√±o de chunk de texto para procesamiento (por defecto: 1000)
- `--chunk-overlap`: Solapamiento entre chunks (por defecto: 200)
- `--model-extract`: Modelo para generaci√≥n Q&A (por defecto: `llama3.1:8b`)
- `--model-validate`: Modelo para validaci√≥n (por defecto: `llama3.1:8b`)
- `--temperature-extract`: Temperatura para generaci√≥n (por defecto: 0.3)
- `--temperature-validate`: Temperatura para validaci√≥n (por defecto: 0.1)
- `--skip-validation`: Omitir paso de validaci√≥n de dataset
- `--include-context/--no-include-context`: Incluir contexto en instrucciones (por defecto: True)
- `--system-prompt`: Prompt de sistema personalizado para formatos conversacionales
- `--verbose, -v`: Mostrar informaci√≥n educativa detallada
- `--explain`: Explicar cada paso y mostrar prompts utilizados

#### Comando Analysis
```bash
extract-to-train analyze [OPTIONS] DATASET_PATH
```

**Opciones:**
- `--detailed`: Mostrar an√°lisis detallado con recomendaciones
- `--export-stats`: Exportar estad√≠sticas a archivo JSON

#### Comando Setup
```bash
extract-to-train setup
```

Verifica la configuraci√≥n del entorno y proporciona gu√≠a educativa.

### Ejemplos de Uso

```bash
# Uso b√°sico con salida educativa
extract-to-train extract document.pdf --verbose

# Generar formato Alpaca para Axolotl/Unsloth
extract-to-train extract document.pdf --format alpaca --output train_data.jsonl

# Generar formato conversacional
extract-to-train extract document.pdf --format sharegpt --max-pairs 50

# Generar formato OpenAI con prompt de sistema personalizado
extract-to-train extract document.pdf \
    --format openai \
    --system-prompt "Eres un experto t√©cnico especializado en conceptos de IA." \
    --output openai_train.jsonl

# Generaci√≥n r√°pida sin validaci√≥n
extract-to-train extract document.pdf --skip-validation --max-pairs 20

# Analizar dataset existente
extract-to-train analyze train_data.jsonl --detailed
```

## üîÑ Pipeline de Procesamiento

### 1. Fase de Extracci√≥n PDF
- **Herramienta**: docling
- **Proceso**: Extraer texto, tablas, metadatos preservando estructura
- **Salida**: Contenido de documento estructurado con referencias de p√°gina

### 2. Fase de Chunking de Contenido  
- **Estrategia**: Chunking basado en secciones l√≥gicas
- **Tama√±o**: Configurable (por defecto 1000 chars)
- **Solapamiento**: Configurable (por defecto 200 chars)
- **Preservaci√≥n**: Mantener contexto y relaciones

### 3. Fase de Generaci√≥n Q&A
- **Modelo**: LLM configurable v√≠a Ollama
- **Estrategia**: Generar tipos de preguntas y dificultades diversas
- **Validaci√≥n**: Verificaciones de calidad en tiempo real durante generaci√≥n
- **Salida**: Pares Q&A estructurados con metadatos

### 4. Fase de Validaci√≥n de Dataset
- **Modelo**: Instancia LLM separada para objetividad
- **Criterios**: Precisi√≥n, completitud, claridad, valor de entrenamiento
- **Proceso**: Validaci√≥n de pares individuales con puntuaci√≥n
- **Salida**: Resultados de validaci√≥n y sugerencias de mejora

### 5. Fase de Exportaci√≥n
- **Formatos**: Alpaca, ShareGPT, OpenAI
- **Salida**: Archivos JSONL optimizados para herramientas de fine-tuning
- **Estad√≠sticas**: An√°lisis integral de dataset

## üß™ Estrategia de Testing

### Objetivo de Cobertura: >90%

#### Tests Unitarios
- Extracci√≥n PDF con archivos mock
- Generaci√≥n Q&A con respuestas LLM mock  
- Validaci√≥n y serializaci√≥n de modelos de datos
- Funciones de conversi√≥n de formato
- Funciones de utilidad y helpers

#### Tests de Integraci√≥n
- Pipeline end-to-end con PDFs de muestra
- Integraci√≥n Ollama (con contenedor Docker o mocks)
- Testing de comandos CLI
- Operaciones de I/O de archivos

#### Datos de Test
- PDFs de muestra de diferentes tipos (acad√©micos, t√©cnicos, reportes)
- Salidas esperadas para testing de regresi√≥n
- Casos extremos (PDFs vac√≠os, archivos corruptos, documentos grandes)

### Estructura de Tests
```
tests/
‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îú‚îÄ‚îÄ test_extractor.py
‚îÇ   ‚îú‚îÄ‚îÄ test_generator.py
‚îÇ   ‚îú‚îÄ‚îÄ test_validator.py
‚îÇ   ‚îú‚îÄ‚îÄ test_models.py
‚îÇ   ‚îî‚îÄ‚îÄ test_utils.py
‚îú‚îÄ‚îÄ integration/
‚îÇ   ‚îú‚îÄ‚îÄ test_pipeline.py
‚îÇ   ‚îú‚îÄ‚îÄ test_cli.py
‚îÇ   ‚îî‚îÄ‚îÄ test_ollama_integration.py
‚îî‚îÄ‚îÄ fixtures/
    ‚îú‚îÄ‚îÄ sample_pdfs/
    ‚îú‚îÄ‚îÄ expected_outputs/
    ‚îî‚îÄ‚îÄ mock_responses/
```

## üìö Caracter√≠sticas Educativas

### Modo Verbose
- Explicaciones paso a paso del proceso
- Justificaci√≥n detr√°s de las elecciones de configuraci√≥n
- Visualizaci√≥n en tiempo real de prompts y respuestas del modelo
- Tips educativos y mejores pr√°cticas

### Transparencia de Prompts
- Plantillas de prompts con control de versiones y explicaciones
- Comentarios explicando decisiones de dise√±o
- Ejemplos alternativos de prompts para aprendizaje

### Estad√≠sticas y An√°lisis
- M√©tricas integrales de dataset
- An√°lisis de distribuci√≥n de calidad
- Estimaci√≥n de conteo de tokens para c√°lculo de costo de fine-tuning
- Recomendaciones para mejora

### Logging Educativo
- Mensajes de log informativos explicando cada paso
- Contexto sobre por qu√© se toman ciertas decisiones
- Insights de rendimiento y tips de optimizaci√≥n

## üîß Configuraci√≥n

### Variables de Entorno
```bash
OLLAMA_HOST=http://localhost:11434
LOG_LEVEL=INFO
MAX_RETRIES=3
TIMEOUT_SECONDS=30
```

### Archivo de Configuraci√≥n (`config.yaml`)
```yaml
models:
  extraction:
    name: "llama3.1:8B"
    temperature: 0.3
    context_window: 4096
  validation:
    name: "deepseek-r1:8B"
    temperature: 0.1
    context_window: 4096

processing:
  chunk_size: 1000
  chunk_overlap: 200
  max_pairs_per_chunk: 5

generation:
  question_types: ["factual", "inferential", "comparative", "analytical"]
  difficulty_levels: ["easy", "medium", "hard"]
  min_answer_length: 50
  max_answer_length: 500

validation:
  min_confidence_score: 0.7
  required_scores:
    accuracy: 7
    completeness: 6
    clarity: 6
    training_value: 7
```

## üìä M√©tricas de Calidad

### Indicadores de Calidad del Dataset
- **Puntuaci√≥n de Diversidad**: Distribuci√≥n a trav√©s de tipos de preguntas y dificultades
- **Puntuaci√≥n de Coherencia**: Alineaci√≥n pregunta-respuesta-contexto
- **Puntuaci√≥n de Cobertura**: Porcentaje del documento fuente cubierto
- **Preparaci√≥n para Entrenamiento**: Compatibilidad con requerimientos de fine-tuning

### Criterios de Validaci√≥n
- **Precisi√≥n**: Correcci√≥n factual basada en contexto fuente
- **Completitud**: Cobertura integral de la pregunta
- **Claridad**: Respuestas claras y bien estructuradas
- **Valor de Entrenamiento**: Efectividad para escenarios de fine-tuning

## üöÄ Fases de Implementaci√≥n

### Fase 1: MVP (Funcionalidad Central)
- Extracci√≥n b√°sica de PDF con docling
- Generaci√≥n simple Q&A con un modelo
- Exportaci√≥n formato Alpaca
- Interfaz CLI b√°sica

### Fase 2: Mejorada (Caracter√≠sticas Completas)
- Soporte de exportaci√≥n multi-formato
- Pipeline de validaci√≥n de dataset
- Modo verbose educativo
- Testing integral

### Fase 3: Pulida (Lista para Producci√≥n)
- Optimizaciones de rendimiento
- Manejo avanzado de errores
- Documentaci√≥n completa
- Tutoriales de ejemplo y mejores pr√°cticas

## üìà M√©tricas de √âxito

### M√©tricas T√©cnicas
- **Cobertura de C√≥digo**: >90%
- **Rendimiento**: Procesar PDF de 50 p√°ginas en <5 minutos
- **Calidad**: >80% de pares generados pasan validaci√≥n
- **Compatibilidad**: Soporte para 3 frameworks principales de fine-tuning

### M√©tricas Educativas
- **Claridad**: Los usuarios entienden cada paso de procesamiento
- **Aprendizaje**: Los usuarios pueden modificar prompts y configuraciones
- **Reproducibilidad**: Resultados consistentes a trav√©s de ejecuciones
- **Documentaci√≥n**: Ejemplos completos y tutoriales

## üîí Consideraciones de Seguridad

- **Validaci√≥n de Entrada**: Sanitizar entradas PDF y rutas de archivos
- **L√≠mites de Recursos**: Prevenir uso excesivo de memoria con PDFs grandes
- **Seguridad de API**: Comunicaci√≥n segura con instancia Ollama
- **Manejo de Archivos**: Operaciones de archivo seguras con manejo apropiado de errores

## üìù Requerimientos de Documentaci√≥n

### Documentaci√≥n de Usuario
- **Gu√≠a de Inicio**: Configuraci√≥n y primera ejecuci√≥n
- **Gu√≠a de Configuraci√≥n**: Explicaciones detalladas de par√°metros
- **Mejores Pr√°cticas**: Tips para generaci√≥n √≥ptima de datasets
- **Resoluci√≥n de Problemas**: Problemas comunes y soluciones

### Documentaci√≥n de Desarrollador
- **Referencia de API**: Documentaci√≥n completa de funciones y clases
- **Gu√≠a de Arquitectura**: Dise√±o del sistema e interacci√≥n de componentes
- **Gu√≠a de Contribuci√≥n**: Configuraci√≥n de desarrollo y proceso de contribuci√≥n
- **Gu√≠a de Testing**: C√≥mo ejecutar y extender tests

## üéØ Entregables del Proyecto

1. **Herramienta CLI Funcional**: Aplicaci√≥n de l√≠nea de comandos lista para usar
2. **Ejemplos Educativos**: PDFs de muestra con salidas esperadas
3. **Tests Integrales**: >90% cobertura con tests de integraci√≥n
4. **Documentaci√≥n**: Gu√≠as completas de usuario y desarrollador
5. **Plantillas de Configuraci√≥n**: Configuraciones optimizadas para diferentes casos de uso
6. **Materiales de Tutorial**: Recursos de aprendizaje paso a paso

Esta especificaci√≥n proporciona un roadmap completo para construir una herramienta educativa y lista para producci√≥n para crear datasets de fine-tuning desde documentos PDF mientras mantiene simplicidad y enfoque en resultados de aprendizaje.
